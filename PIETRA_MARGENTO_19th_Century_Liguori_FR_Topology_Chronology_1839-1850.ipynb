{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9abe376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e99d5e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = 'Liguori_translations_FR_normalized_publishers_translators_places.xlsx'\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "340e6843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a0fe5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dfb7be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G_1839_50 = nx.MultiDiGraph()\n",
    "\n",
    "# Function to extract and sort years chronologically\n",
    "def extract_years(row, cutoff_year0, cutoff_year1):\n",
    "    year = row['First ed.']\n",
    "    subsequent = row['Subsq. ed.']\n",
    "    \n",
    "    # Extract and filter years based on the cutoff year\n",
    "    all_years = []\n",
    "    \n",
    "    if not math.isnan(year) and int(year) > cutoff_year0 and int(year) <= cutoff_year1:\n",
    "    #if isinstance(year, (int, float)) and year < cutoff_year:\n",
    "        all_years.append(int(year))\n",
    "    \n",
    "    if isinstance(subsequent, str):\n",
    "        #subsequent_years = [int(x.split()[0]) for x in subsequent.split(',') if not (math.isnan(x) or not int(x.split()[0]) <= cutoff_year) else None]\n",
    "        subsequent_years = [\n",
    "            int(x.split()[0]) for x in subsequent.split(',')\n",
    "            if x.strip() and not math.isnan(float(x.split()[0])) and cutoff_year0 < int(x.split()[0]) and int(x.split()[0]) <= cutoff_year1\n",
    "            ]\n",
    "        all_years.extend(subsequent_years)\n",
    "\n",
    "    all_years = sorted(all_years)\n",
    "    \n",
    "    return all_years\n",
    "\n",
    "\n",
    "def is_valid_year(x):\n",
    "    try:\n",
    "        year_int = int(x)\n",
    "        return 1838 < year_int and year_int <= 1850\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "\n",
    "filtered_df = df[df['First ed.'].apply(lambda x: x if not (math.isnan(x) or not is_valid_year(x)) else None).notna()]\n",
    "\n",
    "unique_publishers = set()\n",
    "\n",
    "for publishers in filtered_df['Normalized Publisher']:\n",
    "    if isinstance(publishers, str):\n",
    "        unique_publishers.update([publisher.strip() for publisher in publishers.split(';')])\n",
    "    else:\n",
    "        unique_publishers.update([publishers])\n",
    "\n",
    "for publisher in unique_publishers:\n",
    "    G_1839_50.add_node(publisher, publications=[])\n",
    "    \n",
    "\n",
    "for index, row in filtered_df.iterrows():\n",
    "    title = row['Title']\n",
    "    years = extract_years(row, 1838, 1850)\n",
    "    editions = sum(1 for year in years) if years != [] else 0  # Calculate number of editions based on years after 1825 and before 1839\n",
    "    publishers = [publisher.strip() for publisher in row['Normalized Publisher'].split('; ')] if isinstance(row['Normalized Publisher'], str) else [row['Normalized Publisher']]\n",
    "    translator = row['Normalized Translator']\n",
    "    places = [place.strip() for place in row['Publ. place'].split('; ')] if isinstance(row['Publ. place'], str) else [str(row['Publ. place']).strip()]\n",
    "\n",
    "    for publisher in unique_publishers:\n",
    "        if publisher in publishers:\n",
    "            G_1839_50.nodes[publisher]['publications'].append({\n",
    "                'title': title,\n",
    "                'years': years,\n",
    "                'editions': [editions],\n",
    "                'publisher': publishers,\n",
    "                'translator': translator,\n",
    "                'place': places\n",
    "            })\n",
    "\n",
    "\n",
    "for publisher in G_1839_50.nodes():\n",
    "    if 'publications' in G_1839_50.nodes[publisher]:  # Check if 'publications' key exists\n",
    "        magnitude = sum(pub['editions'][0] for pub in G_1839_50.nodes[publisher]['publications'])\n",
    "        G_1839_50.nodes[publisher]['magnitude'] = magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2095fb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(G_1839_50.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e395b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publisher: landriot, Size: 20\n",
      "Publisher: thibaud, Size: 20\n",
      "Publisher: barbou, Size: 12\n",
      "Publisher: mame, Size: 11\n",
      "Publisher: plagaud, Size: 10\n",
      "Publisher: gallienne, Size: 8\n",
      "Publisher: librairie catholique, Size: 7\n",
      "Publisher: casterman, Size: 6\n",
      "Publisher: lesne, Size: 5\n",
      "Publisher: lefort, Size: 5\n",
      "Publisher: ardant, Size: 4\n",
      "Publisher: perisse, Size: 3\n",
      "Publisher: nan, Size: 3\n",
      "Publisher: delsol, Size: 3\n",
      "Publisher: société de saintvictor, Size: 3\n",
      "Publisher: cornillac, Size: 3\n",
      "Publisher: devillario, Size: 2\n",
      "Publisher: vagner, Size: 2\n",
      "Publisher: thomasmalvin, Size: 2\n",
      "Publisher: parent-desbarres, Size: 2\n",
      "Publisher: guyot, Size: 2\n",
      "Publisher: prudhomme, Size: 2\n",
      "Publisher: société des bons lecteurs, Size: 2\n",
      "Publisher: pradel, Size: 1\n",
      "Publisher: merson, Size: 1\n",
      "Publisher: girard, Size: 1\n",
      "Publisher: fr seguin, Size: 1\n",
      "Publisher: bgat, Size: 1\n",
      "Publisher: lagny, Size: 1\n",
      "Publisher: thomas, Size: 1\n",
      "Publisher: leprieur, Size: 1\n",
      "Publisher: pinet, Size: 1\n",
      "Publisher: paul mellier, Size: 1\n",
      "Publisher: belin, Size: 1\n",
      "Publisher: caron, Size: 1\n",
      "Publisher: aubanel, Size: 1\n",
      "Publisher: vanderborght, Size: 1\n",
      "Publisher: tubergue, Size: 1\n",
      "Publisher: desmoulins, Size: 1\n",
      "Publisher: abadie, Size: 1\n",
      "Publisher: mellier, Size: 1\n",
      "Publisher: ardent, Size: 1\n",
      "Publisher: villetcollignon, Size: 1\n",
      "Publisher: lambert, Size: 1\n",
      "Publisher: dieulafoy, Size: 1\n",
      "Publisher: poussielgue, Size: 1\n",
      "Publisher: jacquot, Size: 1\n",
      "Publisher: de lamarzelle, Size: 1\n",
      "Publisher: pornin, Size: 1\n",
      "Publisher: waille, Size: 1\n",
      "Publisher: royer, Size: 1\n",
      "Publisher: heger, Size: 1\n",
      "Publisher: pellerin, Size: 1\n",
      "Publisher: bureau des mlanges religieux, Size: 1\n",
      "Publisher: hanicq, Size: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nodes_with_sizes = [(publisher, data['magnitude']) for publisher, data in G_1839_50.nodes(data=True) if 'magnitude' in data]\n",
    "\n",
    "sorted_nodes = sorted(nodes_with_sizes, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for publisher, size in sorted_nodes:\n",
    "    print(f\"Publisher: {publisher}, Size: {size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396bb191",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0953b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_edge_with_attributes(G, publisher_A, publisher_B, title, source_years, target_years,\n",
    "                             source_translator, target_translator, source_num_editions,\n",
    "                             target_num_editions, source_place, target_place, weight, relation, key):\n",
    "    G.add_edge(publisher_A, publisher_B, title=title, source_years=source_years, target_years=target_years,\n",
    "               source_translator=source_translator, target_translator=target_translator,\n",
    "               source_num_editions=source_num_editions, target_num_editions=target_num_editions,\n",
    "               source_place=source_place, target_place=target_place, weight=weight, relation=relation, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9862ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_edges = set()\n",
    "\n",
    "# Function to add edges between publishers with support for multiple edges of the same type\n",
    "def add_edges_between_publishers(G):\n",
    "    for pub_A, pub_B in itertools.combinations(G.nodes, 2):  # Iterate over pairs of nodes\n",
    "        publications_A = G.nodes[pub_A]['publications']\n",
    "        publications_B = G.nodes[pub_B]['publications']\n",
    "        \n",
    "        # Compare all publications between two publishers\n",
    "        for publication_A in publications_A:\n",
    "            for publication_B in publications_B:\n",
    "                title_A, title_B = publication_A['title'], publication_B['title']\n",
    "                years_A, years_B = publication_A['years'], publication_B['years']\n",
    "                editions_A, editions_B = publication_A['editions'], publication_B['editions']\n",
    "                translators_A, translators_B = publication_A['translator'], publication_B['translator']\n",
    "                publishers_A, publishers_B = set(publication_A['publisher']), set(publication_B['publisher'])\n",
    "                \n",
    "                # Ensure translators_A and translators_B are lists\n",
    "                translators_A = translators_A if isinstance(translators_A, list) else []\n",
    "                translators_B = translators_B if isinstance(translators_B, list) else []\n",
    "\n",
    "                \n",
    "                # Initialize edge counters\n",
    "                edge_counter = 0\n",
    "\n",
    "                # Check for copublication\n",
    "                if (len(publishers_A) == 1 & len(publishers_B) == 1) and title_A == title_B and set(years_A) == set(years_B):\n",
    "                    # Create a unique edge key\n",
    "                    edge_counter = sum(1 for key in existing_edges if f\"copub_{pub_A}_{pub_B}_\" in key) + 1\n",
    "                    edge_key = f\"copub_{pub_A}_{pub_B}_{title_A}_{edge_counter}\"\n",
    "\n",
    "                    # Check if the edge already exists\n",
    "                    if edge_key not in existing_edges:\n",
    "                        weight = max(editions_A[0], editions_B[0])\n",
    "                        add_edge_with_attributes(\n",
    "                            G, pub_A, pub_B, title_A, years_A, years_B, translators_A, translators_B,\n",
    "                            editions_A, editions_B, publication_A['place'], publication_B['place'],\n",
    "                            weight, 'copublication', edge_key\n",
    "                        )\n",
    "                        existing_edges.add(edge_key)\n",
    "\n",
    "                # Check for reprint relation\n",
    "                if set(translators_A) == set(translators_B) and title_A == title_B and years_A and years_B:\n",
    "                    if len(years_A) > 0 and len(years_B) > 0:\n",
    "                        if years_A[0] < years_B[0] and publishers_A != publishers_B:\n",
    "                            edge_counter += 1\n",
    "                            edge_key = f\"reprint_{pub_A}_{pub_B}_{title_A}_{edge_counter}\"\n",
    "\n",
    "                            # Check if the edge already exists\n",
    "                            if edge_key not in existing_edges:\n",
    "                                weight = editions_B[0]\n",
    "                                add_edge_with_attributes(\n",
    "                                    G, pub_A, pub_B, title_A, years_A, years_B, translators_A, translators_B,\n",
    "                                    editions_A, editions_B, publication_A['place'], publication_B['place'],\n",
    "                                    weight, 'reprint', edge_key\n",
    "                                )\n",
    "                                existing_edges.add(edge_key)\n",
    "\n",
    "                # Check for retranslation relation\n",
    "                if set(translators_A) != set(translators_B) and title_A == title_B and years_A and years_B:\n",
    "                    if len(years_A) > 0 and len(years_B) > 0:\n",
    "                        if years_A[0] < years_B[0] and publishers_A != publishers_B:\n",
    "                            edge_counter += 1\n",
    "                            edge_key = f\"retrans_{pub_A}_{pub_B}_{title_A}_{edge_counter}\"\n",
    "\n",
    "                            # Check if the edge already exists\n",
    "                            if edge_key not in existing_edges:\n",
    "                                weight = editions_B[0]\n",
    "                                add_edge_with_attributes(\n",
    "                                    G, pub_A, pub_B, title_A, years_A, years_B, translators_A, translators_B,\n",
    "                                    editions_A, editions_B, publication_A['place'], publication_B['place'],\n",
    "                                    weight, 'retranslation', edge_key\n",
    "                                )\n",
    "                                existing_edges.add(edge_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6482a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "add_edges_between_publishers(G_1839_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d191e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G_1839_50.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66add4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(existing_edges) # G_thru_1825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2f0479e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(existing_edges) # G_1826_38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35ec1260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(existing_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "125d3724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for title, first_ed, subsq_ed, edition, publisher, translator, place in zip(\n",
    "        filtered_df['Title'],\n",
    "        filtered_df['First ed.'],\n",
    "        filtered_df['Subsq. ed.'],\n",
    "        filtered_df['Editions'],\n",
    "        filtered_df['Normalized Publisher'],\n",
    "        filtered_df['Normalized Translator'],\n",
    "        filtered_df['Publ. place']\n",
    "    ):\n",
    "    \n",
    "    publisher_list = [pub.strip() for pub in str(publisher).split(';') if pub.strip()]\n",
    "    \n",
    "    translator_list = [trans.strip() for trans in str(translator).split(';') if trans.strip()]\n",
    "    \n",
    "    place_list = [pl.strip() for pl in str(place).split(';') if pl.strip()]\n",
    "    \n",
    "    if len(publisher_list) > 1:\n",
    "        \n",
    "        for pub_A, pub_B in itertools.combinations(publisher_list, 2):\n",
    "            # Assign a weight based on editions\n",
    "            weight = max(edition, edition)\n",
    "            # Generate a unique edge key for each copublication instance\n",
    "            edge_counter = sum(1 for key in existing_edges if f\"copub_{pub_A}_{pub_B}_\" in key) + 1\n",
    "            edge_key = f\"copub_{pub_A}_{pub_B}_{title}_{edge_counter}\"\n",
    "\n",
    "            # Check if the edge already exists\n",
    "            if edge_key not in existing_edges:\n",
    "                add_edge_with_attributes(\n",
    "                    G_1839_50, pub_A, pub_B, title, [first_ed, subsq_ed], [first_ed, subsq_ed], translator_list, translator_list,\n",
    "                    [edition], [edition], place_list, place_list, weight, 'copublication', edge_key\n",
    "                )\n",
    "                existing_edges.add(edge_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc0ae0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes ordered by outgoing degree:\n",
      "mame 28\n",
      "devillario 22\n",
      "plagaud 21\n",
      "pradel 20\n",
      "gallienne 20\n",
      "landriot 20\n",
      "fr seguin 19\n",
      "thibaud 19\n",
      "pinet 18\n",
      "delsol 12\n",
      "belin 10\n",
      "barbou 9\n",
      "leprieur 9\n",
      "royer 8\n",
      "lesne 8\n",
      "de lamarzelle 7\n",
      "pornin 6\n",
      "thomasmalvin 5\n",
      "aubanel 5\n",
      "dieulafoy 4\n",
      "merson 3\n",
      "guyot 3\n",
      "pellerin 3\n",
      "thomas 2\n",
      "paul mellier 2\n",
      "villetcollignon 2\n",
      "prudhomme 2\n",
      "cornillac 2\n",
      "girard 1\n",
      "caron 1\n",
      "tubergue 1\n",
      "abadie 1\n",
      "parent-desbarres 1\n",
      "librairie catholique 1\n",
      "vagner 0\n",
      "perisse 0\n",
      "bgat 0\n",
      "lagny 0\n",
      "nan 0\n",
      "casterman 0\n",
      "vanderborght 0\n",
      "desmoulins 0\n",
      "mellier 0\n",
      "ardent 0\n",
      "lambert 0\n",
      "poussielgue 0\n",
      "jacquot 0\n",
      "société de saintvictor 0\n",
      "waille 0\n",
      "heger 0\n",
      "société des bons lecteurs 0\n",
      "ardant 0\n",
      "bureau des mlanges religieux 0\n",
      "hanicq 0\n",
      "lefort 0\n",
      "\n",
      "Nodes ordered by incoming degree:\n",
      "ardant 31\n",
      "landriot 25\n",
      "lefort 24\n",
      "thibaud 23\n",
      "cornillac 20\n",
      "delsol 15\n",
      "lesne 15\n",
      "pellerin 14\n",
      "abadie 13\n",
      "villetcollignon 12\n",
      "librairie catholique 12\n",
      "pornin 9\n",
      "aubanel 8\n",
      "dieulafoy 8\n",
      "de lamarzelle 8\n",
      "prudhomme 7\n",
      "thomas 6\n",
      "leprieur 5\n",
      "belin 5\n",
      "plagaud 5\n",
      "ardent 5\n",
      "gallienne 4\n",
      "guyot 4\n",
      "société de saintvictor 3\n",
      "pradel 2\n",
      "barbou 2\n",
      "lagny 2\n",
      "fr seguin 1\n",
      "mame 1\n",
      "nan 1\n",
      "mellier 1\n",
      "parent-desbarres 1\n",
      "lambert 1\n",
      "jacquot 1\n",
      "royer 1\n",
      "devillario 0\n",
      "vagner 0\n",
      "merson 0\n",
      "girard 0\n",
      "perisse 0\n",
      "bgat 0\n",
      "pinet 0\n",
      "paul mellier 0\n",
      "thomasmalvin 0\n",
      "casterman 0\n",
      "caron 0\n",
      "vanderborght 0\n",
      "tubergue 0\n",
      "desmoulins 0\n",
      "poussielgue 0\n",
      "waille 0\n",
      "heger 0\n",
      "société des bons lecteurs 0\n",
      "bureau des mlanges religieux 0\n",
      "hanicq 0\n",
      "\n",
      "Nodes ordered by overall degree:\n",
      "landriot 45\n",
      "thibaud 42\n",
      "ardant 31\n",
      "mame 29\n",
      "delsol 27\n",
      "plagaud 26\n",
      "gallienne 24\n",
      "lefort 24\n",
      "lesne 23\n",
      "devillario 22\n",
      "pradel 22\n",
      "cornillac 22\n",
      "fr seguin 20\n",
      "pinet 18\n",
      "pellerin 17\n",
      "belin 15\n",
      "de lamarzelle 15\n",
      "pornin 15\n",
      "leprieur 14\n",
      "abadie 14\n",
      "villetcollignon 14\n",
      "aubanel 13\n",
      "librairie catholique 13\n",
      "dieulafoy 12\n",
      "barbou 11\n",
      "royer 9\n",
      "prudhomme 9\n",
      "thomas 8\n",
      "guyot 7\n",
      "thomasmalvin 5\n",
      "ardent 5\n",
      "merson 3\n",
      "société de saintvictor 3\n",
      "lagny 2\n",
      "paul mellier 2\n",
      "parent-desbarres 2\n",
      "girard 1\n",
      "nan 1\n",
      "caron 1\n",
      "tubergue 1\n",
      "mellier 1\n",
      "lambert 1\n",
      "jacquot 1\n",
      "vagner 0\n",
      "perisse 0\n",
      "bgat 0\n",
      "casterman 0\n",
      "vanderborght 0\n",
      "desmoulins 0\n",
      "poussielgue 0\n",
      "waille 0\n",
      "heger 0\n",
      "société des bons lecteurs 0\n",
      "bureau des mlanges religieux 0\n",
      "hanicq 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "out_degrees = dict(G_1839_50.out_degree())\n",
    "in_degrees = dict(G_1839_50.in_degree())\n",
    "overall_degrees = {node: out_degrees.get(node, 0) + in_degrees.get(node, 0) for node in G_1839_50.nodes()}\n",
    "\n",
    "nodes_by_out_degree = sorted(out_degrees, key=out_degrees.get, reverse=True)\n",
    "nodes_by_in_degree = sorted(in_degrees, key=in_degrees.get, reverse=True)\n",
    "nodes_by_overall_degree = sorted(overall_degrees, key=overall_degrees.get, reverse=True)\n",
    "\n",
    "print(\"Nodes ordered by outgoing degree:\")\n",
    "for node in nodes_by_out_degree:\n",
    "    print(node, out_degrees[node])\n",
    "\n",
    "print(\"\\nNodes ordered by incoming degree:\")\n",
    "for node in nodes_by_in_degree:\n",
    "    print(node, in_degrees[node])\n",
    "\n",
    "print(\"\\nNodes ordered by overall degree:\")\n",
    "for node in nodes_by_overall_degree:\n",
    "    print(node, overall_degrees[node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68557dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outgoing Weighted Degrees: {'thibaud': 36, 'mame': 35, 'devillario': 29, 'pradel': 29, 'plagaud': 26, 'fr seguin': 23, 'gallienne': 23, 'landriot': 23, 'pinet': 20, 'delsol': 18, 'royer': 12, 'lesne': 12, 'thomasmalvin': 11, 'belin': 11, 'barbou': 10, 'leprieur': 10, 'de lamarzelle': 8, 'pornin': 7, 'aubanel': 6, 'dieulafoy': 5, 'pellerin': 4, 'merson': 3, 'villetcollignon': 3, 'guyot': 3, 'cornillac': 3, 'thomas': 2, 'paul mellier': 2, 'prudhomme': 2, 'girard': 1, 'caron': 1, 'tubergue': 1, 'abadie': 1, 'parent-desbarres': 1, 'librairie catholique': 1, 'vagner': 0, 'perisse': 0, 'bgat': 0, 'lagny': 0, nan: 0, 'casterman': 0, 'vanderborght': 0, 'desmoulins': 0, 'mellier': 0, 'ardent': 0, 'lambert': 0, 'poussielgue': 0, 'jacquot': 0, 'société de saintvictor': 0, 'waille': 0, 'heger': 0, 'société des bons lecteurs': 0, 'ardant': 0, 'bureau des mlanges religieux': 0, 'hanicq': 0, 'lefort': 0}\n",
      "Incoming Weighted Degrees: {'ardant': 53, 'landriot': 42, 'librairie catholique': 32, 'cornillac': 29, 'thibaud': 26, 'lefort': 24, 'delsol': 17, 'lesne': 16, 'pellerin': 14, 'abadie': 13, 'villetcollignon': 12, 'pornin': 9, 'barbou': 8, 'aubanel': 8, 'plagaud': 8, 'dieulafoy': 8, 'de lamarzelle': 8, 'prudhomme': 7, 'thomas': 6, 'leprieur': 5, 'belin': 5, 'ardent': 5, 'pradel': 4, 'gallienne': 4, 'guyot': 4, 'mame': 3, 'société de saintvictor': 3, 'lagny': 2, 'fr seguin': 1, 'mellier': 1, 'parent-desbarres': 1, 'lambert': 1, 'jacquot': 1, 'royer': 1, 'devillario': 0, 'vagner': 0, 'merson': 0, 'girard': 0, 'perisse': 0, 'bgat': 0, 'pinet': 0, 'paul mellier': 0, nan: 0, 'thomasmalvin': 0, 'casterman': 0, 'caron': 0, 'vanderborght': 0, 'tubergue': 0, 'desmoulins': 0, 'poussielgue': 0, 'waille': 0, 'heger': 0, 'société des bons lecteurs': 0, 'bureau des mlanges religieux': 0, 'hanicq': 0}\n",
      "Overall Weighted Degrees: {'landriot': 65, 'thibaud': 62, 'ardant': 53, 'mame': 38, 'delsol': 35, 'plagaud': 34, 'pradel': 33, 'librairie catholique': 33, 'cornillac': 32, 'devillario': 29, 'lesne': 28, 'gallienne': 27, 'fr seguin': 24, 'lefort': 24, 'pinet': 20, 'barbou': 18, 'pellerin': 18, 'belin': 16, 'de lamarzelle': 16, 'pornin': 16, 'leprieur': 15, 'villetcollignon': 15, 'aubanel': 14, 'abadie': 14, 'dieulafoy': 13, 'royer': 13, 'thomasmalvin': 11, 'prudhomme': 9, 'thomas': 8, 'guyot': 7, 'ardent': 5, 'merson': 3, 'société de saintvictor': 3, 'lagny': 2, 'paul mellier': 2, 'parent-desbarres': 2, 'girard': 1, 'caron': 1, 'tubergue': 1, 'mellier': 1, 'lambert': 1, 'jacquot': 1, 'vagner': 0, 'perisse': 0, 'bgat': 0, nan: 0, 'casterman': 0, 'vanderborght': 0, 'desmoulins': 0, 'poussielgue': 0, 'waille': 0, 'heger': 0, 'société des bons lecteurs': 0, 'bureau des mlanges religieux': 0, 'hanicq': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "weights = []\n",
    "\n",
    "outgoing_weighted_degrees = {}\n",
    "incoming_weighted_degrees = {}\n",
    "overall_weighted_degrees = {}\n",
    "\n",
    "for node in G_1839_50.nodes():\n",
    "    successors = []\n",
    "    for node_id in G_1839_50.successors(node):\n",
    "        successors.append(node_id)\n",
    "    weights = []\n",
    "    for u, v, key, attr in G_1839_50.edges(keys=True, data=True):\n",
    "        if (u in successors and v == node) or (u == node and v in successors):\n",
    "            weight = attr['weight']\n",
    "            #weights.append(sum(weight))\n",
    "            weights.append(weight)\n",
    "    #outgoing_weight = sum(sum(G11.edges[node, neighbor]['weight']) for neighbor in G11.successors(node))\n",
    "    outgoing_weighted_degrees[node] = sum(weights)\n",
    "\n",
    "for node in G_1839_50.nodes():\n",
    "    predecessors = []\n",
    "    for node_id in G_1839_50.predecessors(node):\n",
    "        predecessors.append(node_id)\n",
    "    weights = []\n",
    "    for u, v, key, attr in G_1839_50.edges(keys=True, data=True):\n",
    "        if (u in predecessors and v == node) or (u == node and v in predecessors):\n",
    "            weight = attr['weight']\n",
    "            # weights.append(sum(weight))\n",
    "            weights.append(weight)\n",
    "    #incoming_weight = sum(sum(G11.edges[neighbor, node]['weight']) for neighbor in G11.predecessors(node))\n",
    "    incoming_weighted_degrees[node] = sum(weights)\n",
    "\n",
    "for node in G_1839_50.nodes():\n",
    "    overall_weighted_degree = outgoing_weighted_degrees.get(node, 0) + incoming_weighted_degrees.get(node, 0)\n",
    "    overall_weighted_degrees[node] = overall_weighted_degree\n",
    "\n",
    "sorted_outgoing_weighted_degrees = dict(sorted(outgoing_weighted_degrees.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_incoming_weighted_degrees = dict(sorted(incoming_weighted_degrees.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_overall_weighted_degrees = dict(sorted(overall_weighted_degrees.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "print(\"Outgoing Weighted Degrees:\", sorted_outgoing_weighted_degrees)\n",
    "print(\"Incoming Weighted Degrees:\", sorted_incoming_weighted_degrees)\n",
    "print(\"Overall Weighted Degrees:\", sorted_overall_weighted_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ff41c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Source Places: [('Paris', 48), ('Clermont', 40), ('Toulouse', 36), ('Lyon', 33), ('Avignon', 24), ('Carpentras', 22), ('Le Mans', 20), ('Nevers', 18), ('Tours', 16), ('Limoges', 9), ('Vannes', 7), ('Sens', 5), ('Nantes', 3), ('Épinal', 3), ('Nancy', 2), ('Verdun', 2), ('Saint Brieuc', 2), ('Châtillon', 2), ('Amiens', 1), ('Besançon', 1), ('Saint-Gaudens', 1)]\n",
      "Sorted Target Places: [('Clermont', 60), ('Limoges', 33), ('Toulouse', 25), ('Lyon', 25), ('Lille', 24), ('Paris', 21), ('Châtillon', 20), ('Épinal', 14), ('Saint-Gaudens', 13), ('Verdun', 12), ('Tours', 10), ('Avignon', 9), ('Vannes', 8), ('Saint Brieuc', 7), ('Nancy', 6), ('Le Mans', 4), ('Plancy', 3), ('Amiens', 1), ('Besançon', 1)]\n",
      "Sorted Overall Places: [('Clermont', 100), ('Paris', 69), ('Toulouse', 61), ('Lyon', 58), ('Limoges', 42), ('Avignon', 33), ('Tours', 26), ('Le Mans', 24), ('Lille', 24), ('Carpentras', 22), ('Châtillon', 22), ('Nevers', 18), ('Épinal', 17), ('Vannes', 15), ('Saint-Gaudens', 14), ('Verdun', 14), ('Saint Brieuc', 9), ('Nancy', 8), ('Sens', 5), ('Plancy', 3), ('Nantes', 3), ('Amiens', 2), ('Besançon', 2)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "source_place_counter = Counter()\n",
    "target_place_counter = Counter()\n",
    "overall_place_counter = Counter()\n",
    "\n",
    "\n",
    "for publisher_A, publisher_B, data in G_1839_50.edges(data=True):\n",
    "    if isinstance(data['source_place'], list):\n",
    "        source_places = data['source_place']\n",
    "    else:\n",
    "        source_places = [data['source_place']]\n",
    "    if isinstance(data['target_place'], list):\n",
    "        target_places = data['target_place']\n",
    "    else:\n",
    "        target_places = [data['target_place']]\n",
    "\n",
    "    \n",
    "    for i, place_list in enumerate(source_places):\n",
    "        if isinstance(place_list, str):\n",
    "            source_places[i] = [place_list]\n",
    "    \n",
    "    for i, place_list in enumerate(target_places):\n",
    "        if isinstance(place_list, str):\n",
    "            #place_list = [place_list]\n",
    "            target_places[i] = [place_list]\n",
    "            \n",
    "    for place_list in source_places:\n",
    "        for place in place_list:\n",
    "            source_place_counter[place] += 1\n",
    "            \n",
    "    for place_list in target_places:\n",
    "        for place in place_list:\n",
    "            target_place_counter[place] += 1\n",
    "    \n",
    "    for place_list in source_places + target_places:\n",
    "        #if isinstance(place_list, str):\n",
    "            #place_list = [place_list]  # Convert string to list\n",
    "        for place in place_list:\n",
    "            overall_place_counter[place] += 1\n",
    "\n",
    "\n",
    "sorted_source_places = source_place_counter.most_common()\n",
    "sorted_target_places = target_place_counter.most_common()\n",
    "sorted_overall_places = overall_place_counter.most_common()\n",
    "\n",
    "\n",
    "print(\"Sorted Source Places:\", sorted_source_places)\n",
    "print(\"Sorted Target Places:\", sorted_target_places)\n",
    "print(\"Sorted Overall Places:\", sorted_overall_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a95b8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Source Places (Weighted): [('Clermont', 60), ('Paris', 58), ('Toulouse', 49), ('Lyon', 42), ('Carpentras', 29), ('Avignon', 29), ('Le Mans', 23), ('Tours', 20), ('Nevers', 20), ('Sens', 11), ('Limoges', 10), ('Vannes', 8), ('Épinal', 4), ('Nantes', 3), ('Verdun', 3), ('Châtillon', 3), ('Nancy', 2), ('Saint Brieuc', 2), ('Amiens', 1), ('Besançon', 1), ('Saint-Gaudens', 1)]\n",
      "Sorted Target Places (Weighted): [('Clermont', 100), ('Limoges', 61), ('Lyon', 29), ('Châtillon', 29), ('Toulouse', 26), ('Lille', 24), ('Paris', 21), ('Épinal', 14), ('Saint-Gaudens', 13), ('Verdun', 12), ('Tours', 12), ('Avignon', 9), ('Vannes', 8), ('Saint Brieuc', 7), ('Nancy', 6), ('Le Mans', 4), ('Plancy', 3), ('Amiens', 1), ('Besançon', 1)]\n",
      "Sorted Overall Places (Weighted): [('Clermont', 160), ('Paris', 79), ('Toulouse', 75), ('Limoges', 71), ('Lyon', 71), ('Avignon', 38), ('Tours', 32), ('Châtillon', 32), ('Carpentras', 29), ('Le Mans', 27), ('Lille', 24), ('Nevers', 20), ('Épinal', 18), ('Vannes', 16), ('Verdun', 15), ('Saint-Gaudens', 14), ('Sens', 11), ('Saint Brieuc', 9), ('Nancy', 8), ('Plancy', 3), ('Nantes', 3), ('Amiens', 2), ('Besançon', 2)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "source_place_counter_weighted = Counter()\n",
    "target_place_counter_weighted = Counter()\n",
    "overall_place_counter_weighted = Counter()\n",
    "\n",
    "for publisher_A, publisher_B, data in G_1839_50.edges(data=True):\n",
    "    # Get the weight of the current edge\n",
    "    weight = data['weight']\n",
    "    \n",
    "    if isinstance(data['source_place'], list):\n",
    "        source_places = data['source_place']\n",
    "    else:\n",
    "        source_places = [data['source_place']]\n",
    "    if isinstance(data['target_place'], list):\n",
    "        target_places = data['target_place']\n",
    "    else:\n",
    "        target_places = [data['target_place']]\n",
    "\n",
    "    for i, place_list in enumerate(source_places):\n",
    "        if isinstance(place_list, str):\n",
    "            source_places[i] = [place_list]\n",
    "\n",
    "    for i, place_list in enumerate(target_places):\n",
    "        if isinstance(place_list, str):\n",
    "            target_places[i] = [place_list]\n",
    "\n",
    "    for place_list in source_places:\n",
    "        for place in place_list:\n",
    "            # source_place_counter_weighted[place] += weight[0]\n",
    "            source_place_counter_weighted[place] += weight\n",
    "            \n",
    "    for place_list in target_places:\n",
    "        for place in place_list:\n",
    "            # target_place_counter_weighted[place] += weight[0]\n",
    "            target_place_counter_weighted[place] += weight\n",
    "\n",
    "    for place_list in source_places + target_places:\n",
    "        for place in place_list:\n",
    "            # overall_place_counter_weighted[place] += weight[0]\n",
    "            overall_place_counter_weighted[place] += weight\n",
    "\n",
    "sorted_source_places_weighted = source_place_counter_weighted.most_common()\n",
    "sorted_target_places_weighted = target_place_counter_weighted.most_common()\n",
    "sorted_overall_places_weighted = overall_place_counter_weighted.most_common()\n",
    "\n",
    "print(\"Sorted Source Places (Weighted):\", sorted_source_places_weighted)\n",
    "print(\"Sorted Target Places (Weighted):\", sorted_target_places_weighted)\n",
    "print(\"Sorted Overall Places (Weighted):\", sorted_overall_places_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f45b5f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title and number of connections between places it occasioned: ('Visite au S. Sacrement et à\\xa0 la Sainte Vierge', 223) | Source Places: {'Paris', 'Verdun', 'Toulouse', 'Limoges', 'Le Mans', 'Nancy', 'Carpentras', 'Avignon', 'Vannes', 'Nevers', 'Tours', 'Châtillon', 'Saint-Gaudens', 'Lyon', 'Épinal', 'Clermont'} | Target Places: {'Paris', 'Lille', 'Verdun', 'Toulouse', 'Lyon', 'Limoges', 'Le Mans', 'Nancy', 'Avignon', 'Vannes', 'Châtillon', 'Saint-Gaudens', 'Tours', 'Épinal', 'Clermont'}\n",
      "Title and number of connections between places it occasioned: ('Pratique de l\\'amour envers Jésus-Christ, tirée des paroles de S. Paul : \"Caritas patiens est, benigna est\"... par le B. Alphonse de Liguori', 24) | Source Places: {'Limoges', 'Le Mans', 'Saint Brieuc', 'Tours', 'Lyon', 'Clermont'} | Target Places: {'Lyon', 'Limoges', 'Saint Brieuc', 'Clermont'}\n",
      "Title and number of connections between places it occasioned: ('Paraphrase du \"Salve Regina\", par le bienheureux Alphonse de Liguori...', 17) | Source Places: {'Limoges', 'Le Mans', 'Tours', 'Lyon', 'Clermont'} | Target Places: {'Lyon', 'Paris', 'Clermont', 'Tours'}\n",
      "Title and number of connections between places it occasioned: ('Les Vertus de Marie', 12) | Source Places: {'Sens', 'Limoges', 'Saint Brieuc', 'Clermont'} | Target Places: {'Plancy', 'Lille', 'Saint Brieuc', 'Clermont'}\n",
      "Title and number of connections between places it occasioned: ('Traits signalés de la protection et de la miséricorde de Marie, mère de Dieu, par saint Alph.-Marie de Liguory,...', 4) | Source Places: {'Nantes', 'Clermont'} | Target Places: {'Lyon', 'Clermont'}\n",
      "Title and number of connections between places it occasioned: ('Oeuvres complètes du bienheureux A.-M. de Liguori, évêque de Ste-Agathe des Goths; Vol. I-XVI : Oeuvres ascétiques; Vol. XVII-XXII : Oeuvres dogmatiques; Vol. XXIII-XIX : Oeuvres morales', 3) | Source Places: {'Paris'} | Target Places: {'Paris'}\n",
      "Title and number of connections between places it occasioned: ('La Vraie Épouse de Jésus-Christ, ou la Religieuse sanctifiée', 2) | Source Places: {'Lyon'} | Target Places: {'Lyon', 'Paris'}\n",
      "Title and number of connections between places it occasioned: ('Instruction sur le Chemin de La Croix, avec les pratiques de cette dévotion, dédiée à la Très-Sainte Vierge', 1) | Source Places: {'Limoges'} | Target Places: {'Paris', 'Limoges'}\n",
      "Title and number of connections between places it occasioned: (\"Semaine de St Joseph, ou Méditations et prières en l'honneur de ce grand saint pour les sept mercredis ou les sept jours qui précèdent sa fête, par St Liguori...\", 1) | Source Places: {'Lyon'} | Target Places: {'Lyon'}\n",
      "Title and number of connections between places it occasioned: (\"De l'Importance de la prière pour obtenir de Dieu toutes les grÂces et le salut éternel, par le B. Liguori, traduit de l'italien\", 1) | Source Places: {'Le Mans'} | Target Places: {'Lille'}\n",
      "Title and number of connections between places it occasioned: ('Neuvaine au Sacré-Coeur de Jésus', 1) | Source Places: {'Amiens'} | Target Places: {'Amiens'}\n",
      "Title and number of connections between places it occasioned: ('Mois de Marie de saint Alphonse de Liguori, ou Suite de lectures tirées des oeuvres de ce st évêque... par un prêtre du diocèse de Besançon', 1) | Source Places: {'Besançon'} | Target Places: {'Besançon'}\n",
      "Title and number of connections between places it occasioned: (\"Le Guide du pénitent au Sacré Tribunal, ou Court Traité sur le sacrement de pénitence... tiré des oeuvres du B. Liguori et du P. Seigneri, traduit de l'italien par M. J. A. M., prêtre du diocèse de Belley\", 1) | Source Places: {'Lyon'} | Target Places: {'Lyon'}\n",
      "Title and number of connections between places it occasioned: (\"L'Amour des Âmes, ou Réflexions et affectueuses méditations sur la Passion de Jésus-Christ, contenant l'Horloge de la Passion, par S. Alphonse-Marie de Liguori, traduit de l'italien par M. C. D.,...\", 1) | Source Places: {'Clermont'} | Target Places: {'Clermont'}\n",
      "Title and number of connections between places it occasioned: (\"Instruction du peuple sur le décalogue et sur les sacremens : à l'usage des missionnaires ; traduite de l'italien\", 1) | Source Places: {'Clermont'} | Target Places: {'Clermont'}\n",
      "Title and number of connections between places it occasioned: ('La Dévotion au Sacré-Coeur de Jésus et au Saint Coeur de Marie, ou le Salut de la France, précédée de la neuvaine au Sacré-Coeur, par saint Alphonse-Marie de Liguori', 1) | Source Places: {'Clermont'} | Target Places: {'Clermont'}\n",
      "Title and number of connections between places it occasioned: (\"Petits Sermons de S. Alphonse-Marie de Liguori : pouvant servir de lecture spirituelle pour tous les dimanches de l'année / traduits de l'italien par M. Verdier,...\", 1) | Source Places: {'Clermont'} | Target Places: {'Clermont'}\n",
      "Title and weighted number of connections between places it occasioned: ('Visite au S. Sacrement et à\\xa0 la Sainte Vierge', 283) | Source Places: {'Paris', 'Verdun', 'Toulouse', 'Limoges', 'Le Mans', 'Nancy', 'Carpentras', 'Avignon', 'Vannes', 'Nevers', 'Tours', 'Châtillon', 'Saint-Gaudens', 'Lyon', 'Épinal', 'Clermont'} | Target Places: {'Paris', 'Lille', 'Verdun', 'Toulouse', 'Lyon', 'Limoges', 'Le Mans', 'Nancy', 'Avignon', 'Vannes', 'Châtillon', 'Saint-Gaudens', 'Tours', 'Épinal', 'Clermont'}\n",
      "Title and weighted number of connections between places it occasioned: ('Pratique de l\\'amour envers Jésus-Christ, tirée des paroles de S. Paul : \"Caritas patiens est, benigna est\"... par le B. Alphonse de Liguori', 28) | Source Places: {'Limoges', 'Le Mans', 'Saint Brieuc', 'Tours', 'Lyon', 'Clermont'} | Target Places: {'Lyon', 'Limoges', 'Saint Brieuc', 'Clermont'}\n",
      "Title and weighted number of connections between places it occasioned: ('Les Vertus de Marie', 21) | Source Places: {'Sens', 'Limoges', 'Saint Brieuc', 'Clermont'} | Target Places: {'Plancy', 'Lille', 'Saint Brieuc', 'Clermont'}\n",
      "Title and weighted number of connections between places it occasioned: ('Paraphrase du \"Salve Regina\", par le bienheureux Alphonse de Liguori...', 19) | Source Places: {'Limoges', 'Le Mans', 'Tours', 'Lyon', 'Clermont'} | Target Places: {'Lyon', 'Paris', 'Clermont', 'Tours'}\n",
      "Title and weighted number of connections between places it occasioned: (\"L'Amour des Âmes, ou Réflexions et affectueuses méditations sur la Passion de Jésus-Christ, contenant l'Horloge de la Passion, par S. Alphonse-Marie de Liguori, traduit de l'italien par M. C. D.,...\", 6) | Source Places: {'Clermont'} | Target Places: {'Clermont'}\n",
      "Title and weighted number of connections between places it occasioned: ('La Dévotion au Sacré-Coeur de Jésus et au Saint Coeur de Marie, ou le Salut de la France, précédée de la neuvaine au Sacré-Coeur, par saint Alphonse-Marie de Liguori', 5) | Source Places: {'Clermont'} | Target Places: {'Clermont'}\n",
      "Title and weighted number of connections between places it occasioned: ('Traits signalés de la protection et de la miséricorde de Marie, mère de Dieu, par saint Alph.-Marie de Liguory,...', 4) | Source Places: {'Nantes', 'Clermont'} | Target Places: {'Lyon', 'Clermont'}\n",
      "Title and weighted number of connections between places it occasioned: ('Oeuvres complètes du bienheureux A.-M. de Liguori, évêque de Ste-Agathe des Goths; Vol. I-XVI : Oeuvres ascétiques; Vol. XVII-XXII : Oeuvres dogmatiques; Vol. XXIII-XIX : Oeuvres morales', 3) | Source Places: {'Paris'} | Target Places: {'Paris'}\n",
      "Title and weighted number of connections between places it occasioned: ('La Vraie Épouse de Jésus-Christ, ou la Religieuse sanctifiée', 2) | Source Places: {'Lyon'} | Target Places: {'Lyon', 'Paris'}\n",
      "Title and weighted number of connections between places it occasioned: ('Instruction sur le Chemin de La Croix, avec les pratiques de cette dévotion, dédiée à la Très-Sainte Vierge', 1) | Source Places: {'Limoges'} | Target Places: {'Paris', 'Limoges'}\n",
      "Title and weighted number of connections between places it occasioned: (\"Semaine de St Joseph, ou Méditations et prières en l'honneur de ce grand saint pour les sept mercredis ou les sept jours qui précèdent sa fête, par St Liguori...\", 1) | Source Places: {'Lyon'} | Target Places: {'Lyon'}\n",
      "Title and weighted number of connections between places it occasioned: (\"De l'Importance de la prière pour obtenir de Dieu toutes les grÂces et le salut éternel, par le B. Liguori, traduit de l'italien\", 1) | Source Places: {'Le Mans'} | Target Places: {'Lille'}\n",
      "Title and weighted number of connections between places it occasioned: ('Neuvaine au Sacré-Coeur de Jésus', 1) | Source Places: {'Amiens'} | Target Places: {'Amiens'}\n",
      "Title and weighted number of connections between places it occasioned: ('Mois de Marie de saint Alphonse de Liguori, ou Suite de lectures tirées des oeuvres de ce st évêque... par un prêtre du diocèse de Besançon', 1) | Source Places: {'Besançon'} | Target Places: {'Besançon'}\n",
      "Title and weighted number of connections between places it occasioned: (\"Le Guide du pénitent au Sacré Tribunal, ou Court Traité sur le sacrement de pénitence... tiré des oeuvres du B. Liguori et du P. Seigneri, traduit de l'italien par M. J. A. M., prêtre du diocèse de Belley\", 1) | Source Places: {'Lyon'} | Target Places: {'Lyon'}\n",
      "Title and weighted number of connections between places it occasioned: (\"Instruction du peuple sur le décalogue et sur les sacremens : à l'usage des missionnaires ; traduite de l'italien\", 1) | Source Places: {'Clermont'} | Target Places: {'Clermont'}\n",
      "Title and weighted number of connections between places it occasioned: (\"Petits Sermons de S. Alphonse-Marie de Liguori : pouvant servir de lecture spirituelle pour tous les dimanches de l'année / traduits de l'italien par M. Verdier,...\", 1) | Source Places: {'Clermont'} | Target Places: {'Clermont'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize counters for unweighted and weighted titles\n",
    "unweighted_title_counter = Counter()\n",
    "weighted_title_counter = Counter()\n",
    "\n",
    "# Initialize dictionaries to store concatenated source and target places for each title\n",
    "title_source_places = {}\n",
    "title_target_places = {}\n",
    "\n",
    "# Iterate over edges in the graph\n",
    "for publisher_A, publisher_B, data in G_1839_50.edges(data=True):\n",
    "    title = data['title']\n",
    "    weight = data['weight']\n",
    "    \n",
    "    # Increment the unweighted and weighted title counters\n",
    "    unweighted_title_counter[title] += 1\n",
    "    weighted_title_counter[title] += weight\n",
    "    \n",
    "    if isinstance(data['source_place'], list):\n",
    "        source_places = data['source_place']\n",
    "    else:\n",
    "        source_places = [data['source_place']]\n",
    "    if isinstance(data['target_place'], list):\n",
    "        target_places = data['target_place']\n",
    "    else:\n",
    "        target_places = [data['target_place']]\n",
    "\n",
    "    for i, place_list in enumerate(source_places):\n",
    "        if isinstance(place_list, str):\n",
    "            source_places[i] = [place_list]\n",
    "\n",
    "    for i, place_list in enumerate(target_places):\n",
    "        if isinstance(place_list, str):\n",
    "            target_places[i] = [place_list]\n",
    "    \n",
    "    if title not in title_source_places:\n",
    "                title_source_places[title] = [] \n",
    "            \n",
    "    for place_list in source_places:\n",
    "        for place in place_list:\n",
    "            title_source_places[title].append(place)\n",
    "    \n",
    "    if title not in title_target_places:\n",
    "                title_target_places[title] = [] \n",
    "            \n",
    "    for place_list in target_places:\n",
    "        for place in place_list:          \n",
    "            title_target_places[title].append(place)\n",
    "\n",
    "# Sort titles based on unweighted occurrences\n",
    "sorted_unweighted_titles = unweighted_title_counter.most_common()\n",
    "\n",
    "# Sort titles based on weighted occurrences\n",
    "sorted_weighted_titles = weighted_title_counter.most_common()\n",
    "\n",
    "for elem in sorted_unweighted_titles:\n",
    "    print(f\"Title and number of connections between places it occasioned: {elem} | Source Places: {set(title_source_places[elem[0]])} | Target Places: {set(title_target_places[elem[0]])}\")\n",
    "\n",
    "for ele in sorted_weighted_titles:\n",
    "    print(f\"Title and weighted number of connections between places it occasioned: {ele} | Source Places: {set(title_source_places[ele[0]])} | Target Places: {set(title_target_places[ele[0]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "281189dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "G_combined = nx.DiGraph()\n",
    "\n",
    "for u, v, key, attr in G_1839_50.edges(keys=True, data=True):\n",
    "    weight = attr.get('weight', 0)  # Default to 0 if 'weight' is missing\n",
    "\n",
    "    if G_combined.has_edge(u, v):\n",
    "        G_combined[u][v]['weight'] += weight\n",
    "    else:\n",
    "        G_combined.add_edge(u, v, weight=weight)\n",
    "\n",
    "for node, data in G_1839_50.nodes(data=True):\n",
    "    if not G_combined.has_node(node):\n",
    "        G_combined.add_node(node, **data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d1ef70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(G_combined.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d0d2e411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G_combined.edges) # out of the 471 in G_thru_1825 now collapsed into a digraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e3b9caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G_combined.edges) # out of 550 edges in G_1826_38 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc53fe7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G_combined.edges) # out of 272 edges in G_1839_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "325df870",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "closeness_centralities = nx.closeness_centrality(G_combined)\n",
    "\n",
    "betweenness_centralities = nx.betweenness_centrality(G_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a73a0a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eigenvector_centralities = nx.eigenvector_centrality(G_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1677f9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigenvector_centralities = nx.eigenvector_centrality(G_combined, max_iter = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a919b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e35aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted_closeness = sorted(closeness_centralities.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_betweenness = sorted(betweenness_centralities.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_eigenvector = sorted(eigenvector_centralities.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6f44076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ardant', 0.45806100217864926),\n",
       " ('lefort', 0.4273504273504274),\n",
       " ('cornillac', 0.38571428571428573),\n",
       " ('thibaud', 0.35555555555555557),\n",
       " ('pellerin', 0.30458089668615984),\n",
       " ('librairie catholique', 0.28935185185185186),\n",
       " ('landriot', 0.26016260162601623),\n",
       " ('lesne', 0.26016260162601623),\n",
       " ('delsol', 0.25396825396825395),\n",
       " ('villetcollignon', 0.25161030595813205),\n",
       " ('abadie', 0.23703703703703702),\n",
       " ('pornin', 0.23703703703703702),\n",
       " ('dieulafoy', 0.22695035460992904),\n",
       " ('de lamarzelle', 0.22695035460992904),\n",
       " ('prudhomme', 0.20667989417989419),\n",
       " ('ardent', 0.19290123456790123),\n",
       " ('société de saintvictor', 0.18371546149323925),\n",
       " ('plagaud', 0.1807909604519774),\n",
       " ('pradel', 0.16666666666666666),\n",
       " ('guyot', 0.1616161616161616),\n",
       " ('aubanel', 0.14814814814814814),\n",
       " ('thomas', 0.13852813852813853),\n",
       " ('leprieur', 0.13852813852813853),\n",
       " ('mellier', 0.13778659611992947),\n",
       " ('belin', 0.13675213675213677),\n",
       " ('gallienne', 0.1316872427983539),\n",
       " ('barbou', 0.12549019607843137),\n",
       " ('mame', 0.1045751633986928),\n",
       " ('lagny', 0.037037037037037035),\n",
       " ('fr seguin', 0.018518518518518517),\n",
       " (nan, 0.018518518518518517),\n",
       " ('royer', 0.018518518518518517),\n",
       " ('parent-desbarres', 0.018518518518518517),\n",
       " ('lambert', 0.018518518518518517),\n",
       " ('jacquot', 0.018518518518518517),\n",
       " ('devillario', 0.0),\n",
       " ('merson', 0.0),\n",
       " ('girard', 0.0),\n",
       " ('pinet', 0.0),\n",
       " ('paul mellier', 0.0),\n",
       " ('thomasmalvin', 0.0),\n",
       " ('caron', 0.0),\n",
       " ('tubergue', 0.0),\n",
       " ('vagner', 0.0),\n",
       " ('perisse', 0.0),\n",
       " ('bgat', 0.0),\n",
       " ('casterman', 0.0),\n",
       " ('vanderborght', 0.0),\n",
       " ('desmoulins', 0.0),\n",
       " ('poussielgue', 0.0),\n",
       " ('waille', 0.0),\n",
       " ('heger', 0.0),\n",
       " ('société des bons lecteurs', 0.0),\n",
       " ('bureau des mlanges religieux', 0.0),\n",
       " ('hanicq', 0.0)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_closeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95658a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('landriot', 0.08556953179594688),\n",
       " ('delsol', 0.07299091544374563),\n",
       " ('thibaud', 0.0590146750524109),\n",
       " ('pradel', 0.052119729792685775),\n",
       " ('gallienne', 0.017353831819240623),\n",
       " ('plagaud', 0.013475425110645235),\n",
       " ('guyot', 0.009433962264150943),\n",
       " ('mame', 0.0015373864430468205),\n",
       " ('barbou', 0.0013976240391334728),\n",
       " ('cornillac', 0.0005241090146750524),\n",
       " ('prudhomme', 0.00046587467971115766),\n",
       " ('lesne', 0.00040764034474726293),\n",
       " ('belin', 0.00034940600978336826),\n",
       " ('dieulafoy', 5.823433496389471e-05),\n",
       " ('de lamarzelle', 5.823433496389471e-05),\n",
       " ('pornin', 5.823433496389471e-05),\n",
       " ('devillario', 0.0),\n",
       " ('fr seguin', 0.0),\n",
       " ('thomas', 0.0),\n",
       " ('leprieur', 0.0),\n",
       " ('aubanel', 0.0),\n",
       " ('abadie', 0.0),\n",
       " ('villetcollignon', 0.0),\n",
       " ('pellerin', 0.0),\n",
       " ('ardant', 0.0),\n",
       " ('librairie catholique', 0.0),\n",
       " ('lefort', 0.0),\n",
       " ('ardent', 0.0),\n",
       " ('société de saintvictor', 0.0),\n",
       " ('merson', 0.0),\n",
       " (nan, 0.0),\n",
       " ('girard', 0.0),\n",
       " ('pinet', 0.0),\n",
       " ('royer', 0.0),\n",
       " ('paul mellier', 0.0),\n",
       " ('parent-desbarres', 0.0),\n",
       " ('lagny', 0.0),\n",
       " ('thomasmalvin', 0.0),\n",
       " ('caron', 0.0),\n",
       " ('lambert', 0.0),\n",
       " ('tubergue', 0.0),\n",
       " ('jacquot', 0.0),\n",
       " ('mellier', 0.0),\n",
       " ('vagner', 0.0),\n",
       " ('perisse', 0.0),\n",
       " ('bgat', 0.0),\n",
       " ('casterman', 0.0),\n",
       " ('vanderborght', 0.0),\n",
       " ('desmoulins', 0.0),\n",
       " ('poussielgue', 0.0),\n",
       " ('waille', 0.0),\n",
       " ('heger', 0.0),\n",
       " ('société des bons lecteurs', 0.0),\n",
       " ('bureau des mlanges religieux', 0.0),\n",
       " ('hanicq', 0.0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sorted_betweenness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "871f706b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lefort', 0.562705272275513),\n",
       " ('ardant', 0.5507787147017774),\n",
       " ('cornillac', 0.40064489075572035),\n",
       " ('pellerin', 0.24594106945329605),\n",
       " ('thibaud', 0.19854405261300956),\n",
       " ('librairie catholique', 0.18710701223417717),\n",
       " ('lesne', 0.1391088888782531),\n",
       " ('pornin', 0.10567383532347875),\n",
       " ('villetcollignon', 0.10009506526669795),\n",
       " ('delsol', 0.09905880698586582),\n",
       " ('landriot', 0.08640125657736586),\n",
       " ('dieulafoy', 0.08027483165866901),\n",
       " ('de lamarzelle', 0.08027483165866901),\n",
       " ('abadie', 0.06737160993550867),\n",
       " ('prudhomme', 0.04814676900107184),\n",
       " ('ardent', 0.04628313138788746),\n",
       " ('plagaud', 0.032775202484870404),\n",
       " ('pradel', 0.031343269908818784),\n",
       " ('société de saintvictor', 0.030475111241149006),\n",
       " ('aubanel', 0.023582615652896804),\n",
       " ('thomas', 0.01849347434849708),\n",
       " ('guyot', 0.01580802014682505),\n",
       " ('leprieur', 0.014776173846178126),\n",
       " ('gallienne', 0.013055380318262231),\n",
       " ('belin', 0.01122452717875739),\n",
       " ('mellier', 0.01036992611654791),\n",
       " ('barbou', 0.009917377531283546),\n",
       " ('mame', 0.004130944383270541),\n",
       " ('lagny', 5.09537795841361e-13),\n",
       " ('fr seguin', 4.430763442098789e-14),\n",
       " (nan, 4.430763442098789e-14),\n",
       " ('royer', 4.430763442098789e-14),\n",
       " ('parent-desbarres', 4.430763442098789e-14),\n",
       " ('lambert', 4.430763442098789e-14),\n",
       " ('jacquot', 4.430763442098789e-14),\n",
       " ('devillario', 2.013983382772177e-15),\n",
       " ('merson', 2.013983382772177e-15),\n",
       " ('girard', 2.013983382772177e-15),\n",
       " ('pinet', 2.013983382772177e-15),\n",
       " ('paul mellier', 2.013983382772177e-15),\n",
       " ('thomasmalvin', 2.013983382772177e-15),\n",
       " ('caron', 2.013983382772177e-15),\n",
       " ('tubergue', 2.013983382772177e-15),\n",
       " ('vagner', 2.013983382772177e-15),\n",
       " ('perisse', 2.013983382772177e-15),\n",
       " ('bgat', 2.013983382772177e-15),\n",
       " ('casterman', 2.013983382772177e-15),\n",
       " ('vanderborght', 2.013983382772177e-15),\n",
       " ('desmoulins', 2.013983382772177e-15),\n",
       " ('poussielgue', 2.013983382772177e-15),\n",
       " ('waille', 2.013983382772177e-15),\n",
       " ('heger', 2.013983382772177e-15),\n",
       " ('société des bons lecteurs', 2.013983382772177e-15),\n",
       " ('bureau des mlanges religieux', 2.013983382772177e-15),\n",
       " ('hanicq', 2.013983382772177e-15)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02d06b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weighted_closeness = nx.closeness_centrality(G_combined, distance='weight')\n",
    "weighted_betweenness = nx.betweenness_centrality(G_combined, weight='weight')\n",
    "weighted_eigenvector = nx.eigenvector_centrality(G_combined, max_iter = 500, weight='weight')\n",
    "\n",
    "sorted_weighted_closeness = sorted(weighted_closeness.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_weighted_betweenness = sorted(weighted_betweenness.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_weighted_eigenvector = sorted(weighted_eigenvector.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4167142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lefort', 0.39682539682539686),\n",
       " ('thibaud', 0.2882882882882883),\n",
       " ('pellerin', 0.27557319223985893),\n",
       " ('cornillac', 0.2755102040816326),\n",
       " ('ardant', 0.24720752498530277),\n",
       " ('librairie catholique', 0.12580515297906603),\n",
       " ('lesne', 0.06971677559912853),\n",
       " ('pornin', 0.05360134003350083),\n",
       " ('prudhomme', 0.052371375900787664),\n",
       " ('guyot', 0.047619047619047616),\n",
       " ('dieulafoy', 0.0471976401179941),\n",
       " ('de lamarzelle', 0.0471976401179941),\n",
       " ('villetcollignon', 0.0462962962962963),\n",
       " ('ardent', 0.04318684355997789),\n",
       " ('delsol', 0.043184885290148446),\n",
       " ('société de saintvictor', 0.042551742919389984),\n",
       " ('abadie', 0.042328042328042326),\n",
       " ('landriot', 0.04199475065616798),\n",
       " ('plagaud', 0.03965303593556381),\n",
       " ('mellier', 0.039367598891408416),\n",
       " ('lagny', 0.037037037037037035),\n",
       " ('aubanel', 0.036655211912943866),\n",
       " ('pradel', 0.0365296803652968),\n",
       " ('thomas', 0.03567447045707915),\n",
       " ('leprieur', 0.035555555555555556),\n",
       " ('belin', 0.03532008830022075),\n",
       " ('gallienne', 0.034972677595628415),\n",
       " ('mame', 0.028596961572832886),\n",
       " ('barbou', 0.027777777777777776),\n",
       " ('fr seguin', 0.018518518518518517),\n",
       " (nan, 0.018518518518518517),\n",
       " ('royer', 0.018518518518518517),\n",
       " ('parent-desbarres', 0.018518518518518517),\n",
       " ('lambert', 0.018518518518518517),\n",
       " ('jacquot', 0.018518518518518517),\n",
       " ('devillario', 0.0),\n",
       " ('merson', 0.0),\n",
       " ('girard', 0.0),\n",
       " ('pinet', 0.0),\n",
       " ('paul mellier', 0.0),\n",
       " ('thomasmalvin', 0.0),\n",
       " ('caron', 0.0),\n",
       " ('tubergue', 0.0),\n",
       " ('vagner', 0.0),\n",
       " ('perisse', 0.0),\n",
       " ('bgat', 0.0),\n",
       " ('casterman', 0.0),\n",
       " ('vanderborght', 0.0),\n",
       " ('desmoulins', 0.0),\n",
       " ('poussielgue', 0.0),\n",
       " ('waille', 0.0),\n",
       " ('heger', 0.0),\n",
       " ('société des bons lecteurs', 0.0),\n",
       " ('bureau des mlanges religieux', 0.0),\n",
       " ('hanicq', 0.0)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sorted_weighted_closeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bbb247f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('landriot', 0.08427544386663882),\n",
       " ('delsol', 0.07542083760637218),\n",
       " ('pradel', 0.05625436757512229),\n",
       " ('thibaud', 0.054949540326898805),\n",
       " ('gallienne', 0.01971232238527836),\n",
       " ('plagaud', 0.017222426420539626),\n",
       " ('guyot', 0.010414114187699093),\n",
       " ('prudhomme', 0.0018022392236228713),\n",
       " ('de lamarzelle', 0.0014829209535708488),\n",
       " ('pornin', 0.0014829209535708488),\n",
       " ('belin', 0.0012592481670049803),\n",
       " ('cornillac', 0.0009459297981310558),\n",
       " ('pellerin', 0.0009073842145120972),\n",
       " ('leprieur', 0.0008749015562432753),\n",
       " ('mame', 0.0006988120195667365),\n",
       " ('dieulafoy', 0.00069675743155827),\n",
       " ('aubanel', 0.0005978725056293191),\n",
       " ('lesne', 0.00046587467971115766),\n",
       " ('thomas', 0.0004367575122292103),\n",
       " ('villetcollignon', 0.0004258165159632665),\n",
       " ('devillario', 0.0),\n",
       " ('barbou', 0.0),\n",
       " ('fr seguin', 0.0),\n",
       " ('abadie', 0.0),\n",
       " ('ardant', 0.0),\n",
       " ('librairie catholique', 0.0),\n",
       " ('lefort', 0.0),\n",
       " ('ardent', 0.0),\n",
       " ('société de saintvictor', 0.0),\n",
       " ('merson', 0.0),\n",
       " (nan, 0.0),\n",
       " ('girard', 0.0),\n",
       " ('pinet', 0.0),\n",
       " ('royer', 0.0),\n",
       " ('paul mellier', 0.0),\n",
       " ('parent-desbarres', 0.0),\n",
       " ('lagny', 0.0),\n",
       " ('thomasmalvin', 0.0),\n",
       " ('caron', 0.0),\n",
       " ('lambert', 0.0),\n",
       " ('tubergue', 0.0),\n",
       " ('jacquot', 0.0),\n",
       " ('mellier', 0.0),\n",
       " ('vagner', 0.0),\n",
       " ('perisse', 0.0),\n",
       " ('bgat', 0.0),\n",
       " ('casterman', 0.0),\n",
       " ('vanderborght', 0.0),\n",
       " ('desmoulins', 0.0),\n",
       " ('poussielgue', 0.0),\n",
       " ('waille', 0.0),\n",
       " ('heger', 0.0),\n",
       " ('société des bons lecteurs', 0.0),\n",
       " ('bureau des mlanges religieux', 0.0),\n",
       " ('hanicq', 0.0)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sorted_weighted_betweenness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f163f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ardant', 0.5690725027009835),\n",
       " ('landriot', 0.43633061749650864),\n",
       " ('librairie catholique', 0.37456751897078716),\n",
       " ('lefort', 0.36086130913187764),\n",
       " ('cornillac', 0.2460744635552106),\n",
       " ('lesne', 0.19687144786400265),\n",
       " ('pellerin', 0.1749246009591842),\n",
       " ('prudhomme', 0.12794377977507482),\n",
       " ('thibaud', 0.12275266400986226),\n",
       " ('pornin', 0.09279270695979921),\n",
       " ('delsol', 0.08476640872641146),\n",
       " ('villetcollignon', 0.08403611421621995),\n",
       " ('dieulafoy', 0.08177028203894332),\n",
       " ('de lamarzelle', 0.08177028203894332),\n",
       " ('ardent', 0.0695635858059519),\n",
       " ('abadie', 0.06748169418162801),\n",
       " ('plagaud', 0.060747909891418185),\n",
       " ('société de saintvictor', 0.06047743470592447),\n",
       " ('pradel', 0.022852560076699252),\n",
       " ('barbou', 0.012322519692087398),\n",
       " ('guyot', 0.009086151100027445),\n",
       " ('mellier', 0.008188516474673883),\n",
       " ('thomas', 0.005639316872457459),\n",
       " ('aubanel', 0.004939149283548453),\n",
       " ('gallienne', 0.004741682247103898),\n",
       " ('leprieur', 0.0037892098304995645),\n",
       " ('belin', 0.003339103144077401),\n",
       " ('mame', 0.001917484212894026),\n",
       " ('lagny', 1.8844046050637963e-24),\n",
       " ('fr seguin', 1.2995893828026175e-25),\n",
       " (nan, 1.2995893828026175e-25),\n",
       " ('royer', 1.2995893828026175e-25),\n",
       " ('parent-desbarres', 1.2995893828026175e-25),\n",
       " ('lambert', 1.2995893828026175e-25),\n",
       " ('jacquot', 1.2995893828026175e-25),\n",
       " ('devillario', 4.6413906528664945e-27),\n",
       " ('merson', 4.6413906528664945e-27),\n",
       " ('girard', 4.6413906528664945e-27),\n",
       " ('pinet', 4.6413906528664945e-27),\n",
       " ('paul mellier', 4.6413906528664945e-27),\n",
       " ('thomasmalvin', 4.6413906528664945e-27),\n",
       " ('caron', 4.6413906528664945e-27),\n",
       " ('tubergue', 4.6413906528664945e-27),\n",
       " ('vagner', 4.6413906528664945e-27),\n",
       " ('perisse', 4.6413906528664945e-27),\n",
       " ('bgat', 4.6413906528664945e-27),\n",
       " ('casterman', 4.6413906528664945e-27),\n",
       " ('vanderborght', 4.6413906528664945e-27),\n",
       " ('desmoulins', 4.6413906528664945e-27),\n",
       " ('poussielgue', 4.6413906528664945e-27),\n",
       " ('waille', 4.6413906528664945e-27),\n",
       " ('heger', 4.6413906528664945e-27),\n",
       " ('société des bons lecteurs', 4.6413906528664945e-27),\n",
       " ('bureau des mlanges religieux', 4.6413906528664945e-27),\n",
       " ('hanicq', 4.6413906528664945e-27)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_weighted_eigenvector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae81b148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
